We develop a physics-informed deep learning model based on a convolutional neural network(CNN) which uses hierarchical filtering to predict the local existence of asters from the initial filament orientation field

# Neural Network Architecture
Our binary classification model is designed to predict the occurrence of actin aster formation at the center of 64×64 grayscale images representing the initial actin orientation field. The convolutional architecture consists of three sequential convolutional layers with increasing filter sizes to capture spatial hierarchies in the input images. The first convolutional layer uses 32 filters of size 3×3, followed by a 2×2 max pooling operation, reducing the spatial dimensions while maintaining significant features. This is followed by a second convolutional block with 64 filters of size 3×3 and another 2×2 max pooling layer. The final convolutional block includes 128 filters of size 3×3, followed by a 2×2 max pooling operation. Each convolutional layer employs ReLU (Rectified Linear Unit) activations to introduce non-linearity, facilitating the learning of complex patterns.

Additionally, our architecture employs a convolutional attention feature extraction module based on the self-attention generative adversarial network (SAGAN) discriminator, which is introduced after the convolutional layers to recalibrate the feature maps using attention mechanisms. This self-attention layer computes query, key, and value convolutions, followed by softmax normalization to generate attention weights23. We refer to the above convolutional blocks and the self-attention layer as the “feature extraction” module. The flattened output from the self-attention layer is passed to a dense fully connected layer with 512 units and ReLU activations. A dropout layer with a rate of 0.5 is added to prevent overfitting by randomly setting half of the input units to zero during training. The final layer of the network is a single neuron with a sigmoid activation function, producing a binary output that predicts the presence (with the output “1”) or absence (with the output “0”) of an actin aster. We refer to the above fully connected layers as the “classification” module.
The neural network was implemented using TensorFlow v. 2.15.1.

# Data Preparation
The input data consist of orientation fields acquired from a sliding window process applied to the actin fluorescence images obtained in our experiments. Each resulting image has a resolution of 64×64 pixels, with a spatial resolution of 0.408 µm/pixel. The orientation field (θ) was extracted from the actin fluorescence images using the Fiji/ImageJ plugin function OrientationJ24, which returns the angle in radians from 0 to π. These angles were rescaled by a factor of 255/π, resulting in 8-bit grayscale images where each pixel value ranged from 0 to 255. A total of 118,524 training and 39,281 validation samples were generated by applying a 64×64 pixels sliding window (4-pixel step size in x and y directions) to these grayscale images (1210 × 1650 pixels). This dataset includes images representing both the presence and absence of actin asters collected from n = 5 independent F-actin experiments with the same experimental setup. The dataset for test (i.e., prediction) were collected from another n = 5 independent F-actin experiments different from those for training and validation, but with the same experimental setup.

# Training and Evaluation 
The model is trained using the ADAM optimizer with a learning rate of 1e^(-4) and a binary cross-entropy loss function. The training data were generated using the Keras ImageDataGenerator, where pixel values were rescaled by 1/255. The model was trained over 100 epochs, with each epoch comprising 248 batches, and validated over 80 steps per epoch on the validation set. The entire set of experiments was conducted on a system equipped with an Intel(R) Xeon(R) Gold 6226 CPU @ 2.70GHz.

